{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Neural Signal and Signal Processing (NEURO-421)</h2>\n",
    "<hr style=\"clear:both\"></hr>\n",
    "<h1><font color='black'>Multivariate approaches: PCA, ICA, PLS, K-means</font></h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-info'>\n",
    "In this lab, we are going to apply different multivariate techniques to fMRI data: PCA, Group ICA, K-means and PLS.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from scipy.stats import zscore\n",
    "from scipy.io import loadmat\n",
    "from IPython.display import Image\n",
    "\n",
    "save_results = 'results/'\n",
    "if not os.path.exists(save_results):\n",
    "    os.makedirs(save_results)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for the dataset:\n",
    "- Download the data folder found in this link [here](https://drive.google.com/file/d/1kqDjve05xHxs76p1UymxubMFdPNur-My/view?usp=sharing)\n",
    "- Move the downloaded data to MyFiles so that it remains and is also accessible from NeuroDesk (to see data of MyFiles from NeuroDesk refer to announcement [here](https://moodle.epfl.ch/mod/forum/discuss.php?d=107654))\n",
    "- Unzip it so that your folder structure should look like this\n",
    "\n",
    "```.\n",
    "├── ICA_data\n",
    "├── PCA_data\n",
    "├── PLS_data\n",
    "└── results\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill-in the path to unzipped folder\n",
    "data_path = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PCA \n",
    "<br>\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #805AD5; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "        <p style='margin-top:1em; text-align:center'><b>Principal Component Analysis in fMRI</b></p>\n",
    "        <p style='text-indent: 10px;'> fMRI analysis often requires to extract most representative spatial patterns from runs. A geometrical analogy would be to determine the main directions of a cloud of points. </p>\n",
    "        <p style='text-indent: 10px;'> In this part we will use principal component analysis (PCA) to exactly perform the operations mentioned above. In here, the cloud of points would be the different volumes (TRs) and the dimensionality of our points would be of the order of a volume.</p>\n",
    "        <p> In the context of fMRI data analysis, PCA can be used to extract the most representative spatial patterns from the data. By treating timepoints as samples and voxels as features, PCA helps in identifying the main directions of variance in the brain activity data. </p>\n",
    "    </span>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Brief theoretical description</u>:\n",
    "PCA is a statistical technique used to simplify a dataset by reducing its dimensionality while retaining most of the variation in the data. It achieves this by transforming the data into a new coordinate system where the greatest variances by any projection of the data come to lie on the first coordinates (called principal components), the second greatest variances on the second coordinates, and so on.\n",
    "\n",
    "Given a dataset $\\mathbf{X}$ with $n$ samples and $p$ features, PCA aims to find a set of orthogonal vectors (principal components) that capture the maximum variance in the data. The steps involved in PCA are:\n",
    "\n",
    "1. **Center the Data**: Center the data by subtracting the mean of each feature.\n",
    "    $$\n",
    "    \\mathbf{X}_{\\text{centered}} = \\mathbf{X} - \\mathbf{\\mu}\n",
    "    $$\n",
    "    where $\\mathbf{\\mu}$ is the mean vector of $\\mathbf{X}$.\n",
    "\n",
    "2. **Compute the Covariance Matrix**:\n",
    "    $$\n",
    "    \\mathbf{C} = \\frac{1}{n-1} \\mathbf{X}_{\\text{centered}}^T \\mathbf{X}_{\\text{centered}}\n",
    "    $$\n",
    "\n",
    "3. **Eigen Decomposition**: Calculate the eigenvalues and eigenvectors of the covariance matrix $\\mathbf{C}$.\n",
    "    $$\n",
    "    \\mathbf{C} \\mathbf{v}_i = \\lambda_i \\mathbf{v}_i\n",
    "    $$\n",
    "    where $\\lambda_i$ are the eigenvalues and $\\mathbf{v}_i$ are the corresponding eigenvectors.\n",
    "\n",
    "4. **Sort Eigenvalues and Eigenvectors**: Sort the eigenvalues in descending order and arrange the corresponding eigenvectors to form the principal components.\n",
    "\n",
    "5. **Select Eigenvectors of interest**: Select eigenvectors associated with largest eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(op.join(data_path,'PCA_data/ds114_sub009_t2r1.nii'))\n",
    "affine = img.affine\n",
    "data = np.asanyarray(img.dataobj)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "\n",
    "We can think of the shape of the data as two parts - the first 3 values are the 3D shape of the individual volumes, and the last value is the number of volumes. Put the 3D shape into a variable vol_shape and the number of volumes into a variable n_vols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make variables:\n",
    "# 'vol_shape' for shape of volumes\n",
    "# 'n_vols' for number of volumes\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying PCA, a question that we need one needs to ask is, what are the features and what are the samples? Here in this context, we will take the timepoints as being the “samples” and the voxels to be the features. Note however that per volume there are many useless voxels, such as the background. We will first be removing it, and flattening volume into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Note: In our case the background is encoded as 0 \n",
    "# you can consider that the first volume's background \n",
    "# voxels are the same as all following volumes\n",
    "\n",
    "slice_non_background = ...\n",
    "# Vectorize : Taking only non-zero voxels into a vector \n",
    "# (NOTE: that the order is important)\n",
    "samples = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up we will be removing the spatial mean across timepoints from each timepoints. Calculate the mean spatial pattern and perform the substraction operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Calculate the mean across columns\n",
    "spatial_means = ...\n",
    "# Row means copied n_vols times so that we substract for each timepoint the spatial mean\n",
    "row_means = ...\n",
    "# Subtract the means for each row, put the result into X\n",
    "X = samples - row_means\n",
    "\n",
    "# Verify that the spatial mean behaves as expected after substraction\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying PCA on the temporal axis (i.e features being the spatial map and samples being the timepoints), we are effectively finding representatives of spatial clusters. In our application, the components we find would then intuitively be patterns that \"represent\" best the full run. \n",
    "\n",
    "While we can set `nb_components` to an arbitrary value , the number of relevant components is to selected either arbitrarily (after visualization) or according to various criterion such as:\n",
    "- [Elbow Criterion](https://en.wikipedia.org/wiki/Elbow_method_(clustering))\n",
    "\n",
    "To apply PCA, we can use scikit-learn PCA model: [PCA](https://scikit-learn.org/dev/modules/generated/sklearn.decomposition.PCA.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "nb_components = 10 # Arbitrary number\n",
    "\n",
    "# YOUR CODE HERE \n",
    "pca = PCA(...)\n",
    "pca.fit(...) # NOTE: Takes matrix of shape (nb_samples, nb_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "ratios = pca.explained_variance_ratio_\n",
    "cumulative_ratios = np.cumsum(pca.explained_variance_ratio_)\n",
    "nb_clusters = 3\n",
    "\n",
    "ax[0].plot(np.arange(1, len(ratios)+1), ratios, label='explained variance ratios', c='k')\n",
    "ax[0].scatter([nb_clusters], [ratios[nb_clusters-1]], [150], marker='x', color='r', label='cutoff')\n",
    "ax[1].plot(np.arange(1, len(cumulative_ratios)+1), cumulative_ratios, label='cumulative explained variance', c='k')\n",
    "ax[1].hlines(y=cumulative_ratios[nb_clusters-1], xmin=0, xmax=len(ratios)-1, linestyle='--', color='r', label='cutoff')\n",
    "\n",
    "for k in range(2):\n",
    "    ax[k].set_xlabel('Components #', size=15)\n",
    "    ax[k].legend(prop={'size':15})\n",
    "    ax[k].tick_params(axis='both', which='major', labelsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we selected components of interest let's bring the vectors back to the original spatial domain. Practically speaking, you will have to reshape the components back to the original volume shape, while remembering that we removed the background voxels. (Hint: `slice_non_background` would be of use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE \n",
    "pca_clusters = ... # List of spatial components (you should have in the list volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import mean_img\n",
    "mean_img_ = mean_img(img)\n",
    "visual_idx = 0\n",
    "plot_stat_map(nib.Nifti1Image(pca_clusters[visual_idx], affine), bg_img=mean_img_, threshold=0,\n",
    "               cut_coords=[0,0,0], black_bg=True,\n",
    "              title=f'PCA Cluster {visual_idx}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Temporal K-means\n",
    "<br>\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #805AD5; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "        <p style='margin-top:1em; text-align:center'><b>Temporal K-means in fMRI</b></p>\n",
    "        <p style='text-indent: 10px;'> In the same spirit as for PCA, K-means is a clustering method enabling components extraction.\n",
    "        Leveraging a given definition of distance (i.e cosine distance, euclidean distance etc...), K-means finds distance minimizing components to cover all samples</p>\n",
    "        <p style='text-indent: 10px;'> Similar to how we applied PCA, we will consider timepoints to be samples and voxels to be features. Clustering would yield the main spatial patterns that \"appear\" during the timecourse.</p>\n",
    "    </span>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<u>Brief theoretical description</u>:\n",
    "K-means is a popular clustering algorithm used to partition a dataset into $K$ distinct, non-overlapping subsets (clusters). The standard algorithm aims to minimize the within-cluster variance, which is the sum of squared distances between each data point and the centroid of its assigned cluster. (the formulation can also be extended to minimize a different distance metric)\n",
    "\n",
    "Given a dataset $\\mathbf{X} = \\{ \\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_n \\}$ with $n$ samples, the steps involved in K-means are:\n",
    "\n",
    "1. **Initialization**: Randomly select $K$ initial centroids $\\{ \\mathbf{\\mu}_1, \\mathbf{\\mu}_2, \\ldots, \\mathbf{\\mu}_K \\}$.\n",
    "\n",
    "2. **Assignment Step**: Assign each data point to the nearest centroid based on the Euclidean distance. For each data point $\\mathbf{x}_i$, find the closest centroid $\\mathbf{\\mu}_j$:\n",
    "    $$\n",
    "    c_i = \\arg\\min_{j} \\| \\mathbf{x}_i - \\mathbf{\\mu}_j \\|^2\n",
    "    $$\n",
    "    where $c_i$ is the cluster assignment for data point $\\mathbf{x}_i$.\n",
    "\n",
    "3. **Update Step**: Recalculate the centroids as the mean of all data points assigned to each cluster:\n",
    "    $$\n",
    "    \\mathbf{\\mu}_j = \\frac{1}{|C_j|} \\sum_{\\mathbf{x}_i \\in C_j} \\mathbf{x}_i\n",
    "    $$\n",
    "    where $C_j$ is the set of data points assigned to cluster $j$ and $|C_j|$ is the number of data points in cluster $j$.\n",
    "\n",
    "4. **Convergence**: Repeat the assignment and update steps until the centroids no longer change or the change is below a predefined threshold.\n",
    "\n",
    "The objective of K-means is to minimize the within-cluster sum of squares (WCSS), also known as the inertia:\n",
    "$$\n",
    "\\text{WCSS} = \\sum_{j=1}^{K} \\sum_{\\mathbf{x}_i \\in C_j} \\| \\mathbf{x}_i - \\mathbf{\\mu}_j \\|^2\n",
    "$$\n",
    "\n",
    "This inertia can be used to decide in a less arbitrary way the numbers of cluster.\n",
    "\n",
    "Additional description and formulation can be found [here](https://en.wikipedia.org/wiki/K-means_clustering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply K-Means, we can use scikit-learn KMeans implementation: [KMeans](https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "# We will be using the same data for as in PCA\n",
    "# Thus the background are also not taken in feature vectors\n",
    "X_kmeans = deepcopy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "max_nb_clusters = 10\n",
    "avg_dist_samples = []\n",
    "for nb_cluster in range(1, max_nb_clusters):\n",
    "    kmeans = KMeans(n_clusters=nb_cluster, random_state=0, n_init=\"auto\").fit(X_kmeans.T)\n",
    "    avg_dist_samples.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(7,5))\n",
    "\n",
    "ax.plot(np.arange(1, len(avg_dist_samples)+1), avg_dist_samples, label='explained variance ratios', c='k')\n",
    "\n",
    "ax.set_xlabel('Clusters #', size=15)\n",
    "ax.legend(prop={'size':15})\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "nb_clusters = ... # The number of clusters you want\n",
    "kmeans = ...\n",
    "\n",
    "kmeans_clusters = [] # List of spatial components (you should have in the list volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.image import mean_img\n",
    "mean_img_ = mean_img(img)\n",
    "visual_idx = 0\n",
    "plot_stat_map(nib.Nifti1Image(kmeans_clusters[visual_idx], affine), bg_img=mean_img_, threshold=0,\n",
    "               cut_coords=[49,37,00], black_bg=True,\n",
    "              title=f'K-means Cluster {visual_idx}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PLS\n",
    "<br>\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #805AD5; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "        <p style='margin-top:1em; text-align:center'><b>Partial Least Squares in fMRI</b></p>\n",
    "        <p style='text-indent: 10px;'> While both PCA and Partial Least Squares (PLS) employ the same method of Singular Value Decomposition (or eigendecomposition of the covariance matrices), they are applied on different samples. PLS is used to find the fundamental relation between two sample sets through decomposition of the covariance of the two sets.</p>\n",
    "        <p style='text-indent: 10px;'> In this part we will use PLS in combination with behavioural scores specific to each subjects, and determine relationship between the two spaces of fMRI and behavioural scores across subjects. Some examples of behavioural scores in neuroimaging include medical condition, age, personality scores obtained through questionnaires etc...</p>\n",
    "    </span>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Brief theoretical description</u>:\n",
    "Partial Least Squares (PLS) is a statistical method used to find the fundamental relations between two matrices (predictor and response variables) by projecting them into a new space. It is particularly useful when the predictor variables are highly collinear or when the number of predictors exceeds the number of observations.\n",
    "\n",
    "Given two matrices $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ (predictor variables) and $\\mathbf{Y} \\in \\mathbb{R}^{n \\times q}$ (response variables), PLS aims to find the latent vectors $\\mathbf{L_X}$ and $\\mathbf{L_Y}$ such that:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\mathbf{L_X} \\mathbf{W}^T + \\mathbf{E}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{Y} = \\mathbf{L_Y} \\mathbf{Q}^T + \\mathbf{F}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{L_X}$ and $\\mathbf{L_Y}$ are the scores (latent variables), $\\mathbf{W}$ and $\\mathbf{Q}$ are the loadings, and $\\mathbf{E}$ and $\\mathbf{F}$ are the residuals.\n",
    "\n",
    "The steps involved in PLS are:\n",
    "\n",
    "1. **Standardize the Data**: Center and scale the data matrices $\\mathbf{X}$ and $\\mathbf{Y}$.\n",
    "\n",
    "2. **Compute the Covariance Matrix**:\n",
    "    $$\n",
    "    \\mathbf{R} = \\mathbf{Y} \\mathbf{X}^T\n",
    "    $$\n",
    "\n",
    "3. **Decompose the Covariance Matrix**: Perform Singular Value Decomposition (SVD) on the covariance matrix $\\mathbf{R}$:\n",
    "    $$\n",
    "    \\mathbf{R} = \\mathbf{U} \\mathbf{D} \\mathbf{V}^T\n",
    "    $$\n",
    "    where $\\mathbf{U}$ and $\\mathbf{V}$ are the left and right singular vectors, and $\\mathbf{D}$ is the diagonal matrix of singular values.\n",
    "\n",
    "4. **Calculate the Latent vectors**:\n",
    "    $$\n",
    "    \\mathbf{L_X} =  \\mathbf{V}^T \\mathbf{X}\n",
    "    $$\n",
    "    $$\n",
    "    \\mathbf{L_Y} =  \\mathbf{U}^T\\mathbf{Y}\n",
    "    $$\n",
    "By association, you notice that the loadings information are contained in the singular vectors.\n",
    "\n",
    "PLS maximizes the covariance between the scores of $\\mathbf{X}$ and $\\mathbf{Y}$, ensuring that the extracted components explain as much variance as possible in both matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the PLS analysis, we are going to use $n=20$ subjects with one contrast map (image, dim: [91, 109, 91] ) per subject. So in total, the number of input imaging data ($\\textbf{X}$) is 20 flattened contrast maps ($X_{im} \\in {\\rm I\\!R^{d_{im} \\times n}}, d_{im}= 902629, n = 20$) ). \n",
    "    \n",
    "For the behavioural input data ($\\textbf{Y}$), two behavioural scores per subjects are used ($Y_{beh} \\in {\\rm I\\!R^{d_{beh} \\times n}}, d_{beh}= 2, n = 20$) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read contrast maps of all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Read  contrast maps of all subjects and build the X matrix\n",
    "data_dir_template = op.join(data_path,'PLS_data/sub_{}/contrastMap.nii')\n",
    "\n",
    "N_subj = 20                      # Number of subjects\n",
    "tmp    = nib.load(data_dir_template.format(1))\n",
    "x1, y1, z1 = tmp.shape              # voxel size of the contrast maps\n",
    "\n",
    "tmp    = tmp.get_fdata().flatten()\n",
    "N_vox  = tmp.shape[0]    # Number of voxels\n",
    "del tmp\n",
    "\n",
    "#* initialize X\n",
    "X      = np.zeros((N_vox, N_subj)) # voxel_num X subj_num\n",
    "\n",
    "for i in range(N_subj):\n",
    "    voxel_array = nib.load(data_dir_template.format(i+1)).get_fdata().flatten()\n",
    "    X[:,i]      = voxel_array.copy()\n",
    "    \n",
    "X      = zscore(X, axis = 0) # z-scoring voxel activity across subjects\n",
    "X      = np.nan_to_num(X,0) # replace nan with 0s\n",
    "\n",
    "print(\"X matrix size: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read behavioral data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Read behavioral data and build the Y matrix\n",
    "behVar = loadmat(op.join(data_path, 'PLS_Data/behavior.mat'))['behVar']\n",
    "\n",
    "Y = np.zeros(behVar.shape) # size: N_beh x N_subj\n",
    "Y[0,:] = zscore(behVar[0,:])    # z-scoring of the first measure\n",
    "Y[1,:] = zscore(behVar[1,:])    # z-scoring of the second measure\n",
    "\n",
    "print(\"Y matrix size: \", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the cross-correlation matrix R and apply SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Build the cross-correlation matrix (R)\n",
    "R     = np.dot(Y,X.T); # size: N_beh x N_vox\n",
    "print(\"R matrix size: \", R.shape)\n",
    "\n",
    "#* Do Singular Value Decomposition (SVD) of R \n",
    "# (Note that numpy has inbuilt function for SVD)\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html\n",
    "# U: N_beh x N_beh, D: N_beh x 1, V.T: N_beh x N_vox\n",
    "# Remember to that you do not need to compute the full matrix\n",
    "# YOUR CODE HERE\n",
    "U,D,V = ...\n",
    "\n",
    "print(\"U matrix size :\", U.shape, \"D matrix size :\", D.shape, \"V matrix size :\", V.shape)\n",
    "\n",
    "#* Get the Latent Variables LVs\n",
    "# Lx (size: N_beh x N_subj)\n",
    "# Ly= (size: N_beh x N_subj)\n",
    "# YOUR CODE HERE\n",
    "Lx = ...\n",
    "Ly = ...\n",
    "\n",
    "print(\"Latent var x :\", Lx.shape, \"Latent var y :\", Ly.shape)\n",
    "print('Number of singular values is equal to the number of behavioral measures: ', D.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot singular values, behavioral components and spatial components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Plot singular values explaining the covariance between brain contrast maps and behavioral measures\n",
    "\n",
    "plt.figure(dpi=90)\n",
    "plt.bar([1,2], D,color='royalblue')\n",
    "plt.xticks([1, 2], ['Singular Value 1', 'Singular Value 2'])\n",
    "plt.title(\"The singular values explaining the covariance between brain contrast map and behavioral measures\")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Print the Sigular values\n",
    "print(\"\\n The Singular values: \", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular values derived from the covariance matrix show the amount of covariance explained by their corresponding left and right singular vectors. Comparing among singular values allow to understand the relative importance of a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Plot the behavioral components (matrix U)\n",
    "\n",
    "# Plot Behavioral Component U1\n",
    "plt.bar([1,2], U[0,:], color=['lightcoral','royalblue'])\n",
    "plt.xticks([1, 2], ['Behavioral Score 1', 'Behavioral Score 2'])\n",
    "plt.title(\"Behavioral component U1\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Behavioral Component U2\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patterns found from the behavioral components highlight a certain profiles of behaviours (e.g low score 1 and high score 2). These profiles are associated to a spatial pattern. Intuitively, subjects (since we are computing covariance across subjects) that exhibit such a behaviour profile, also exhibits the associated spatial pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Information needed for plotting\n",
    "#* Read T1-weighted template\n",
    "T1w_img = nib.load(op.join(data_path, 'PLS_data/T1w_restore_brain.nii'))\n",
    "\n",
    "# Get affine transform\n",
    "affine = nib.load(data_dir_template.format(1)).affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Plot the spatial components (matrix V)\n",
    "print('Spatial Component V1')\n",
    "V1_img = nib.Nifti1Image(np.reshape(V[:,0],(x1, y1, z1)), affine)\n",
    "\n",
    "#* Plot different views\n",
    "desired_views = ['z', 'ortho']\n",
    "for view_ in desired_views:\n",
    "    plot_stat_map(V1_img, display_mode=view_, title='Spatial Component V1',\n",
    "                    colorbar=True, black_bg=True, bg_img=T1w_img, threshold=2*np.std(V[:,0]),)\n",
    "                    #output_file=save_results + \"pls_spatial_V1_{}.png\".format(view_)) # uncomment to save plot\n",
    "        \n",
    "print('Spatial Component V2')  \n",
    "# YOUR CODE HERE\n",
    "V2_img = ...\n",
    "\n",
    "#* Plot different views\n",
    "desired_views = ['z', 'ortho']\n",
    "for view_ in desired_views:\n",
    "    plot_stat_map(V2_img, display_mode=view_, title='Spatial Component V2',\n",
    "                colorbar=True, black_bg=True, bg_img=T1w_img, threshold=2*np.std(V[:,1]),)\n",
    "                #output_file=save_results + \"pls_spatial_V2_{}.png\".format(view_)) # uncomment to save plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the area highlighted correspond to Posterior Cingulate Cortex (PCC) and the Medial Prefrontal Cortex (mPFC) - belonging to the so called DMN - and that those regions contribute significantly to the brain-behavior covariance matrix R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Spatial & Temporal ICA \n",
    "<br>\n",
    "<div class=\"warning\" style='background-color:#90EE90; color: #805AD5; border-left: solid #805AD5 4px; border-radius: 4px; padding:0.7em;'>\n",
    "    <span>\n",
    "        <p style='margin-top:1em; text-align:center'><b>Temporal / Spatial - Independant Component Analysis in fMRI</b></p>\n",
    "        <p style='text-indent: 10px;'> A different yet similar method to PCA, to perform component extraction is to use ICA. ICA works on the assumption of underlying source to be statistically independent and often finds these sources by maximizing non gaussianity of sources.</p>\n",
    "        <p style='text-indent: 10px;'> In this section we show multiple applications of ICA, temporally, spatially (toy example) and in a group setting (real example). Temporal and spatial ICA differs in whether samples are timepoints or voxels.</p>\n",
    "    </span>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Brief theoretical description</u>: Independent Component Analysis (ICA) is a computational technique used to separate a multivariate signal into additive, independent components. It is particularly useful in the field of signal processing and data analysis, where the goal is to identify underlying factors or sources from observed data.\n",
    "\n",
    "Given a set of observed signals $\\mathbf{X}$, ICA assumes that these signals are linear mixtures of some unknown independent sources $\\mathbf{S}$, combined through an unknown mixing matrix $\\mathbf{A}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\mathbf{A} \\mathbf{S}\n",
    "$$\n",
    "\n",
    "The objective of ICA is to estimate both the mixing matrix $\\mathbf{A}$ and the source signals $\\mathbf{S}$, such that the components of $\\mathbf{S}$ are statistically independent. This can be achieved by finding an unmixing matrix $\\mathbf{W}$ such that:\n",
    "\n",
    "$$\n",
    "\\mathbf{S} = \\mathbf{W} \\mathbf{X}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{W}$ is the inverse of the mixing matrix $\\mathbf{A}$.\n",
    "To find such a mixing (unmixing) matrix, various criterion can be used. \n",
    "ICA typically maximizes the non-Gaussianity of the source signals, as measured by metrics such as negentropy or kurtosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the main process, let's start with a toy-example: a 2D image (x-y) whose pixels are associated to a time-series. To simplify and simulate that this 2D image might change in time, we will consider 3 channels (3 different states that correspond to the ground truth 3 components that we want to emulate). \n",
    "\n",
    "In this way we are trying to simplify what we have in real data fMRI: a volume (3D) that represents the brain with its time-varying activity (4th dimension).\n",
    "\n",
    "Let's start with generating a simulated image that is characterized by 3 clear groups that we want to distinguish and identify with ICA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTRs=100 # number of timepoints in the fMRI timecourse\n",
    "nComps=3 # number of ground-truth components\n",
    "\n",
    "# put together synthetic data (2D x time)\n",
    "t=range(0,nTRs) \n",
    "pS=8 # patch size (size of each small square/ground truth group)\n",
    "iS=40 # image size\n",
    "\n",
    "I = np.zeros([3,iS,iS])\n",
    "T = np.empty([3,1,1,nTRs])\n",
    "\n",
    "# channel 0\n",
    "I[0,:,:]=np.zeros([iS,iS])\n",
    "I[0,:,:][0:0+pS,0:0+pS]=1\n",
    "T[0]=np.random.gamma(10,5,[1,1,nTRs])\n",
    "# channel 1\n",
    "I[1,:,:]=np.zeros([iS,iS])\n",
    "I[1,:,:][10:10+pS,10:10+pS]=1\n",
    "T[1]=np.random.gamma(5,3,[1,1,nTRs])\n",
    "# channel 2\n",
    "I[2,:,:]=np.zeros([iS,iS])\n",
    "I[2,:,:][20:20+pS,20:20+pS]=1\n",
    "T[2]=np.random.gamma(3,2,[1,1,nTRs])\n",
    "\n",
    "# plot ground truth images and time courses of the 3 channels, with the corresponding timeseries\n",
    "# Hint: use imshow for the matrix\n",
    "\n",
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply ICA, we can use scikit-learn ICA implementation: [ICA](https://scikit-learn.org/dev/modules/generated/sklearn.decomposition.FastICA.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake fMRI data (in 3D instead of 4D)\n",
    "# shaping the data into 3D data object\n",
    "\n",
    "data=np.zeros([iS,iS,nTRs])\n",
    "for i in range(nComps):\n",
    "    # repeat the 3 states that we want to identify with the spatial ICA\n",
    "    repeatedI = np.array([I[i] for x in range(nTRs)]).T\n",
    "    data=data+repeatedI*np.tile(T[i],[iS,iS,1])\n",
    "\n",
    "# RUN Spatial ICA\n",
    "\n",
    "## FastICA (reorient data in 2D matrix)\n",
    "## Lecture slides show convention: 1 observation in 1 row\n",
    "## FastICA Python toolbox assumes 1 observation in 1 column\n",
    "\n",
    "x = np.reshape(data,[iS*iS, nTRs])\n",
    "print(\"The X matrix has dimensions {} and it's going to be used as input to spatial or temporal ICA. \\n\\\n",
    "Be careful for the distinction of the 2!\\n\".format(x.shape))\n",
    "\n",
    "# perform ICA using the algorithm FastICA imported from sklearn.decomposition \n",
    "# (CHECK THE DOCUMENTATION TO SEE HOW TO USE IT)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "## First: use ICA on the SPATIAL axis\n",
    "icas = ...\n",
    "icasig_space = icas.fit_transform(...)  # Spatial source signals\n",
    "\n",
    "## Then apply again ICA but on the temporal axis \n",
    "icat = ... #, random_state=9\n",
    "icasig_time = icat.fit_transform(...)  # Temporal source signals\n",
    "\n",
    "\n",
    "## Then reshape spatial sources into 2D images\n",
    "C = np.empty([nComps, iS, iS])\n",
    "for i in range(nComps):\n",
    "    C[i]=np.reshape(icasig_space[:,i],[iS,iS])\n",
    "    \n",
    "print(\"The shape of C is :\", C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to re-run the same code doing 2 changes at the time:\n",
    "\n",
    "1) Increasing the value of the variable of the patch size `pS` to 12, meaning that we will create a small overlap between the blocks;\n",
    "\n",
    "2) Changing the number of components of only the ICA (keeping the ground truth to 3).\n",
    "\n",
    "Run the ICA again a few times and observe the results. What can you say with respect to the sorting and sign of the components? What about increasing the patch size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot spatial and temporal ICA sources similarly as before:\n",
    "# the 3 NxN matrices (in space) with the respective time components stored in the variable icasig_t\n",
    "\n",
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group ICA \n",
    "\n",
    "For the Group ICA analysis, we are going to use data from studyforrest. Subjects are watching the movie \"forrest gump\" during fMRI acquisition. Here we take $n=15$ subjects with 200 smoothed volumes (image dim: [61, 73, 61] ) per subject. So in total, the number of input imaging data  concatenated across subjects is: $$X \\in {\\rm I\\!R^{(n _{subj}\\times n_{images}) \\times d}}$$ with $$n_{subj} = 15, n_{images}=200, d = 271633$$\n",
    "\n",
    "Note that we only take a small part of the movie (1/8th)\n",
    "\n",
    "Citation: Hanke, M., Adelhöfer, N., Kottke, D. et al. A studyforrest extension, simultaneous fMRI and eye gaze recordings during prolonged natural stimulation. Sci Data 3, 160092 (2016). https://doi.org/10.1038/sdata.2016.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "path_func_img = op.join(data_path, 'ICA_data/StudyForest/s01run1/s6wCov_rfrun-1_bold001.nii')\n",
    "img_ex = nib.load(path_func_img)\n",
    "\n",
    "# Get affine transform -- check nibabel library for more info!\n",
    "affine = nib.load(path_func_img).affine\n",
    "x,y,z = img_ex.shape\n",
    "\n",
    "N_vol=200\n",
    "N_subj=8 ## NOTE: You can increase or decrease the number of subjects\n",
    "N_tot=N_vol*N_subj\n",
    "\n",
    "#* Initialize X\n",
    "X = np.zeros((N_tot,x*y*z)) # total_timepoints(15subj*200timepoints) x voxel_num\n",
    "i = 0\n",
    "n_nii  = 0\n",
    "nb_subj_counted=0\n",
    "for root, dirs, files in sorted(os.walk(op.join(data_path, 'ICA_data/StudyForest/'))):\n",
    "    if len(files)!= 0:\n",
    "        nb_subj_counted=nb_subj_counted+1 \n",
    "        if nb_subj_counted > N_subj:\n",
    "            break\n",
    "        print(f\"Loading subject {nb_subj_counted}\")\n",
    "    for j in trange(len(files)):\n",
    "        file = sorted(files)[j]\n",
    "        if file.endswith('.nii'):\n",
    "            if nb_subj_counted<N_subj+1:\n",
    "                X[n_nii,:] = nib.load(root+'/'+file).get_fdata().flatten()\n",
    "                n_nii+=1\n",
    "\n",
    "X = zscore(X, axis = 1) # across subjects\n",
    "X = np.nan_to_num(X,0) # nan to 0s\n",
    "print(\"X matrix size: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the data in FSLeyes or here using nibabel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Build brain mask to restrict analysis within the brain\n",
    "icbms = datasets.fetch_icbm152_2009()\n",
    "masker = NiftiMasker(mask_img=icbms.mask)\n",
    "plot_stat_map(icbms.mask, black_bg=True, title='the brain mask', colorbar=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-info'>\n",
    "\n",
    "**Note:** In the lecture's slides the ICA model was defined as $X = S A$.  The matrix $A$ was the mixing matrix. Here, the Fast ICA model is defined as: $S = X W$. The matrix $W$ is the un-mixing matrix (inverse of $A$).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Run FastICA on X -- check \n",
    "\n",
    "S_dict = {}\n",
    "\n",
    "# assign the variable nb_components to be the list of components (try 3-5 values )\n",
    "\n",
    "nb_components =  [4,]#10]#20, 60 ...]\n",
    "\n",
    "## NOTE that 60 components can be computational costly\n",
    "\n",
    "#* We will transpose the matrix X so that ICA algorithm operates on the voxels dimension.\n",
    "#* In other words, the estimated sources (S) should be have dimensionality [#voxels]\n",
    "\n",
    "for n in nb_components:\n",
    "    print(f\"Processing component {n}\")\n",
    "    # run PCA as a preprocessing step for ICA with twice the number of components\n",
    "    n2=2*n\n",
    "    ### YOUR CODE HERE\n",
    "    pca = ...\n",
    "    H = pca.fit_transform(...)  # Reconstruct signals based on orthogonal components\n",
    "    \n",
    "    # Reminder: Fast ICA model S = X W\n",
    "    print(\"Running FastICA with n = %d components\" %n)\n",
    "\n",
    "    ica = FastICA(n_components=n, random_state=1, max_iter=200)\n",
    "    S_ = ica.fit_transform(...)  # Get the estimated sources (S)\n",
    "\n",
    "    print(S_.shape)\n",
    "    W_ = ica.components_ # Get the estimated un-mixing matrix (W) -- will not be used further on\n",
    "    S_dict[n] = S_ # store the results in a dictionary\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of the estimated Sources is: {}\".format(S_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Read T1-weighted template\n",
    "T1w_img = nib.load(op.join(data_path, 'PLS_data/T1w_restore_brain.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#* Plot the group-level independent components for the different number of requested components.\n",
    "## Here you can use only 3 components to reduce the plots\n",
    "## e.g. uncomment this if you used more than 3 values before\n",
    "# nb_components = nb_components[:3]\n",
    "\n",
    "for n in nb_components:\n",
    "    print('Number of components: ',n)\n",
    "    S_ = S_dict[n].copy()\n",
    "    for idx, s in enumerate(S_.T[:min(4, S_.T.shape[0]),:]): # plot min(4, #comp_estimated) components , change 10 with 4 to plot less\n",
    "        s_img = nib.Nifti1Image(np.reshape(s, (x,y,z)), affine)\n",
    "        data = masker.fit_transform(s_img)\n",
    "        masked_ = masker.inverse_transform(data) # mask the components\n",
    "        plot_stat_map(masked_, display_mode=\"z\", title='Case of {} estimated components: comp #{}'.format(n,idx+1),\n",
    "                      colorbar=True, black_bg=True, threshold=2*np.std(s), bg_img=T1w_img,)\n",
    "                      #output_file=save_results + \"ICA_components_{}_n_{}.png\".format(idx,n)) # uncomment to save plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, copy-paste the cell above but change the display mode of the `plot_stat_map` function to be `ortho` instead of `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "#* Plot the group-level independent components for the different number of requested components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection points: observe what happens when increasing the number of components:\n",
    "\n",
    "Using more independent components doesn't always provide more useful information!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conn_grad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
