{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Neural Signal and Signal Processing (NEURO-421)</h2>\n",
    "<hr style=\"clear:both\"></hr>\n",
    "<h1><font color='black'>Functional connectivity, graphs and connectomes</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <p><b> You can run the notebook as a simple jupyter notebook with no need of FSLeyes:\n",
    "        \"jupyter notebook lab_7_FC_graphs_connectome.ipynb\"! </b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to make sure that you have all required Python libraries installed. Once you have done that, run the cell below it to import all the libraries you will be using, declare some useful functions and to set up your environment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx\n",
    "!pip install pygsp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section imports the needed libraries and defines the used functions:\n",
    "import numpy as np, os\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import pygsp\n",
    "from pygsp import graphs\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "from sklearn.svm import LinearSVC\n",
    "from nilearn.datasets import fetch_atlas_aal\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Functional connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen in class, one of the most intuitive approach to estimate functional connectivity is performing simple Pearson correlations of a seed region with respect to all the other regions. This information will give us information on how the activity of the seed regions correlate with the rest of the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load brain region names\n",
    "CBmat = scipy.io.loadmat(\"./FC_graphs_data/CB\")\n",
    "CB = CBmat['CB'].tolist()\n",
    "CB = np.squeeze(np.asarray(CB).tolist())\n",
    "# Load test adjacency matrix\n",
    "Testmat = scipy.io.loadmat(\"./FC_graphs_data/Test\")\n",
    "Test = Testmat['Test'].tolist()\n",
    "Test = np.squeeze(np.asarray(Test).tolist())\n",
    "# Load all time courses per region per subject\n",
    "TCSmat=scipy.io.loadmat(\"./FC_graphs_data/TCS\")\n",
    "TCS=TCSmat['TCS'].tolist()\n",
    "TCS = np.squeeze(np.asarray(TCS).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with only one subject for simplicity (the first one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = TCS[0, :,:]  # we will have the 90 brain regions activity over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a region to be the seed \n",
    "seed = 10 \n",
    "\n",
    "# plot the time course of the seed\n",
    "### YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take from the AAL atlas the labels of each brain region\n",
    "brain_regions_labels = fetch_atlas_aal()['labels'][:90]\n",
    "\n",
    "# Check your seed what region is it?\n",
    "\n",
    "### YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some brain regions that you are interested in seeing and consider how their function correlate with your seed\n",
    "\n",
    "# plot the results of the correlations and interpret your results\n",
    "\n",
    "### YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to change the seed and re-run the cell. \n",
    "\n",
    "#### Reflection point: \n",
    "\n",
    "Interpret the results: what can you say on the values of correlations across brain regions with respect to the seed selected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute a region-based approach: we will compute the correlation across all region to compute a full functional connectivity matrix. This approach gives us more info of the possible functional network that are correlating across the brain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View_A() is a useful function for plotting the functional connectivity matrix (FC)\n",
    "def View_A(X,labels, labels_on=True,size=14,grid=True):\n",
    "    N=X.shape[0]\n",
    "    plt.rcParams[\"figure.figsize\"] = (size,size)\n",
    "    plt.imshow(X, cmap=\"jet\")\n",
    "    plt.xlim([N,0])\n",
    "    plt.ylim([0,N])\n",
    "    plt.colorbar()\n",
    "    if labels_on==False:\n",
    "        labels=['']*X.shape[0]\n",
    "    locs, labs = plt.xticks()           # Get locations and labels\n",
    "    plt.xticks(np.arange(0,N), labels, rotation=90, fontsize=7)\n",
    "    plt.yticks(np.arange(0,N), labels, fontsize=7)\n",
    "    if grid==True:\n",
    "        plt.grid(color='k', linestyle='-', linewidth=1.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by filling in the `ComputeAdjacency()` function. This function takes the time courses of one subject as an argument, and returns a $90\\times 90$ connectivity matrix reflecting the synchrony between time courses as computed by Pearsonâ€™s correlation coefficient (as implemented in the function [`numpy.corrcoef`](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html)). \n",
    "\n",
    "The function takes as a parameter:\n",
    " * `X` (NumPy Array): the time courses per region for ONE subject, i.e. a matrix of size 90x1190,\n",
    "\n",
    "And returns as parameter:\n",
    " * `output` (NumPy Array): connectivity matrix of size $90\\times 90$, where the entry $(i,j)$ corresponds to the correlation coefficient between $i_{th}$ and $j_{th}$ time course (rows of `X`). Diagonal values of the matrix should also be set to zero. \n",
    "\n",
    "<!---\n",
    "<div alert = 'alert-alert info'>\n",
    "\n",
    "**HINT**: Two functions that you might find useful are [`numpy.corrcoef`](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html) and [`numpy.diag`](https://numpy.org/doc/stable/reference/generated/numpy.diag.html)\n",
    "<\\div>--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the ComputeAdjacency() function using the description given above. \n",
    "# Note- Don't forget to set the diagonal values of the matrix to zero.\n",
    "\n",
    "# def ComputeAdjacency(X): \n",
    "#     return ............\n",
    "\n",
    "### YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section computes and plots the adjacency matrices for three subjects\n",
    "A_sub1 = ComputeAdjacency(TCS[0,:,:])\n",
    "A_sub2 = ComputeAdjacency(TCS[1,:,:])\n",
    "A_sub8 = ComputeAdjacency(TCS[7,:,:])\n",
    "View_A(A_sub1,CB)\n",
    "View_A(A_sub2,CB)\n",
    "View_A(A_sub8,CB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection point:\n",
    "\n",
    "Take a close look at the adjacency matrix plotted above (if you want to see matrices for other subjects, you can change the index of the first dimension of the variable TCS in the lab).\n",
    "\n",
    "What can we say about recurring patterns of functional connectivity?\n",
    "Look in particular at occipital regions (Cal, Cun, Lin, OccSup, OccInf) across the 3 subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before computing graph metrics, connectivity matrices need to be made binary. To do so, you will have to fill in the function `BinarizeAdjacency()`, which takes a non-binary $90\\times 90$ connectivity matrix and a density fraction value (in the range $[0,1]$) as inputs, and returns a binary connectivity matrix. For example, a $0.5$ density value means that only the $50\\%$ strongest connections must be retained in the output matrix. We have to be careful about the fact that we want to only consider the upper diagonal elements of the matrix (excluding diagonal elements themselves) for the calculations. \n",
    "\n",
    "Complete the code of the function `BinarizedAdjacency`. The function takes as parameters:\n",
    " * `A` (2D NumPyArray): non-binary adjacency matrix A, and \n",
    " * `rho` (scalar): the edge density\n",
    " \n",
    "It returns `A2`, a connectivity matrix of the same size as `A`, where $\\rho*100\\%$ of the coefficients have been binarized to 1, and the rest to 0. (Note: in the example above $\\rho = 0.5$).\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "\n",
    "**Note:** the function already includes certain lines of code at the beginning and the end of the body, respectively converting a matrix's upper entries into a vector, and converting a vector into a symmetric matrix.\n",
    "\n",
    "**Hint:** You can use the function [`np.argsort`](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html) to sort the indices (pay attention to the default sorting type). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinarizeAdjacency(A,rho):\n",
    "    #Do not change the following three lines for extracting off-diagonal entries\n",
    "    N = A.shape[0] #find the size of the matrix\n",
    "    # Find the indices of the upper triangle\n",
    "    ind = np.triu_indices(N, k=1)\n",
    "    # Vectorize the element (strictly) above the main diagonal of the adjacency\n",
    "    vec = A[ind] \n",
    "    \n",
    "    ### YOUR CODE\n",
    "    \n",
    "    ## HINTS: \n",
    "    # Consider rho as a threshold in percentage -> you might consider to look for the percentile to \n",
    "    # define a threshold for binarizing the vector \n",
    "    \n",
    "    # or alternative think of sorting the values of the vector\n",
    "    # and take the rho % (e.g. 50%) of the indexes of that vector to be set to 1\n",
    "    \n",
    "    # Binarize the vector vec, and keep the result in the variable vec2 (which should have only 1s and 0s)\n",
    "    \n",
    "    \n",
    "    # Declare output vector vec2 copying it\n",
    "    vec2 = vec.copy()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # DO NOT CHANGE the following lines for converting a vector of off-diagonal entries into a matrix\n",
    "    # Declare A2\n",
    "    A2 = np.zeros((N,N))\n",
    "    # Set upper triangle to the data of vec2\n",
    "    A2[ind] = vec2\n",
    "    # Add it to its transpose, to fill the lower triangle while\n",
    "    A2=A2+A2.T\n",
    "    # Make sure that the diagonal is filled with 0s\n",
    "    A2 = A2 - np.diag(np.diag(A2))\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation on the adjacency matrix from `A_sub1` declared above, using the `View_A()` function for visualization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we calculate a few examples\n",
    "Bin10 = BinarizeAdjacency(A_sub1,0.1)\n",
    "Bin50 = BinarizeAdjacency(A_sub1,0.5)\n",
    "Bin80 = BinarizeAdjacency(A_sub1,0.8)\n",
    "\n",
    "# Plot \n",
    "\n",
    "#(1)Binarized Adjacency, edge_density=0.1,\n",
    "#(2)Binarized Adjacency, edge_density=0.5, and\n",
    "#(3)Binarized Adjacency, edge_density=0.8 \n",
    "#using the View_A() function defined previously\n",
    "\n",
    "#Ex- \n",
    "#plt.title(\"Test Adjacency\")\n",
    "#View_A(...,...,size=8,labels_on=False,grid=False)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Graph Metrics Evaluation\n",
    "\n",
    "Now that we have preprocessed and binarized the *Adjacency Matrix*, we need to evaluate it. The metric that we will mainly consider is the nodal clustering coefficient. Look back at your course notes if needed to understand the mathematical definition, the value boundaries and the physiological interpretation of this brain connectivity measure.\n",
    "\n",
    "For all subjects, we will compute the nodal clustering coefficient at different edge densities (from 0.05 to 0.95, by increments of 0.1). We use the function `ComputeC` to do so, defined at the beginning of the notebook. This function takes a binary adjacency matrix of size $N\\times N$ as input and returns a $N$-element nodal clustering coefficient vector. It clusters using the implementation by *NetworkX* in `nx.algorithms.cluster.clustering`. Look at the [documentation](https://networkx.org/documentation/networkx-2.4/reference/algorithms/generated/networkx.algorithms.cluster.clustering.html) for further details on this function.\n",
    "\n",
    "Run the next cell to calculate the nodal clustering coefficient per node per adjacency matrix for every subject. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ComputeC takes a binary adjacency matrix of size NxN as input and returns a N-element nodal clustering coefficient vector\n",
    "# you can use nx.algorithms.cluster.clustering \n",
    "# HINTs:\n",
    "# 1) use the function (nx.convert_matrix.from_numpy_matrix to convert the adjacency matrix or define a graph\n",
    "# 2) BE CAREFUL: nx.convert_matrix.from_numpy_matrix needs the matrix to be INT type (convert the adjacency matrix to integers)\n",
    "\n",
    "def ComputeC(adj1):\n",
    "    \n",
    "    ### YOUR CODE\n",
    "    \n",
    "    # ccoefs = ...\n",
    "    \n",
    "    return np.asarray(list(ccoefs.values()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = np.zeros((10,1))\n",
    "c = np.zeros((54,10,90))\n",
    "for sub in range(0,54):\n",
    "    for rho_ind in range(0,10):\n",
    "        rho[rho_ind,0] = 0.1 * rho_ind + 0.05\n",
    "        adj = BinarizeAdjacency(np.squeeze(ComputeAdjacency(TCS[sub,:,:])),rho[rho_ind,0])\n",
    "        c[sub, rho_ind, :] = ComputeC(adj)\n",
    "rho_vec = rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the outcome by plotting all the 90 nodal traces as a function of edge density for a few subjects. You can change the subjects by change the three numbers in the first for loop. Each line in the following plots corresponds to one of the 90 nodes in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the iterable to plot different subjects\n",
    "for sub in [1, 2, 8]:\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    # Iterate through each node and add to graph\n",
    "    for node in range(0,90):\n",
    "        plt.plot(rho, c[sub,:,node], label=str(node))\n",
    "    # Format graph\n",
    "    plt.xlabel(\"Edge Density\",fontsize=14)\n",
    "    plt.ylabel(\"Clustering Coefficient\",fontsize=14)\n",
    "    plt.title(\"Subject No. \" + str(sub) + ' (each color represents a certain ROI)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection point:\n",
    "\n",
    "The fact that for small edge densities, the ratio of the real (measured) to random graph is much larger than 1 is enough to claim that the brain is structured: Information flows more efficiently than in a random network. Thus, the brain is a small world network. But remember to consider also the **path length**! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to compare the obtained results to the ones of a random graph\n",
    "model with similar edge density. Using the function [`networkx.erdos_renyi_graph`](https://networkx.org/documentation/networkx-1.10/reference/generated/networkx.generators.random_graphs.erdos_renyi_graph.html), which\n",
    "takes as input parameters:\n",
    " * `n` (int): the number of nodes, and\n",
    " * `p` (float): the probability of connection, i.e. edge density.\n",
    "\n",
    "It returns a graph structure.\n",
    "\n",
    "Complete the next cell to generate a random graph of 90 nodes for the range of density values probed above. We will extract the adjacency matrix description of the graph, and compute the ratio between the subject-wise and the random nodal clustering coefficient values. Visualize the evolution of this parameter, for all nodes, with increasing edge density, averaging across subjects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section calculates the clustering coefficient per node for random graphs\n",
    "# with different edge densitiy (10 values between 0 and 1) and calculates the ratio between\n",
    "# previously calculated clustering coefficients of brain networks and those of the random graphs (i.e. \n",
    "# normalized clustering coefficients)\n",
    "c_rand = np.zeros((54,10,90))\n",
    "for sub in range(0,54):\n",
    "    counter=-1\n",
    "    for edge_density in rho:\n",
    "        counter += 1\n",
    "        # Generate a random graph of 90 nodes for the range of density values probed above\n",
    "        ## YOUR CODE HERE\n",
    "        # rand_graph = ...\n",
    "        \n",
    "        adj = nx.adjacency_matrix(rand_graph).todense()\n",
    "        c_rand[sub, counter, :] = ComputeC(adj)\n",
    "ratio = np.divide(c, c_rand, out=np.zeros_like(c), where=c_rand!=0)\n",
    "c_average = np.mean(ratio, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block plots the NORMALIZED clustering coefficient averaged over subjects versus edge density\n",
    "# As before Each (color) line corresponds to one of the 90 nodes in the graph\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "for node in range(0,90):\n",
    "    plt.plot(rho, c_average[:,node], label=str(node))\n",
    "plt.xlabel(\"Edge Density\",fontsize=14)\n",
    "plt.ylabel(\"Clustering Coefficient\",fontsize=14)\n",
    "plt.title(\"Average (over subjects) Normalized (by random graphs) Clustering Coefficient\")\n",
    "plt.show()\n",
    "\n",
    "# This block plots the clustering coefficient versus edge density for a random graph\n",
    "# Each (color) line corresponds to one of the 90 nodes in the graph\n",
    "sub = 1\n",
    "for node in range(0,90):\n",
    "    plt.plot(rho, c_rand[sub,:,node], label=str(node))\n",
    "plt.xlabel(\"Edge Density\",fontsize=14)\n",
    "plt.ylabel(\"Clustering Coefficient\",fontsize=14)\n",
    "plt.title(\"Clustering Coefficient for Random Graphs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now observe what happens when nodes of the network are shut down in sequence. We will investigate two cases: \n",
    " * one in which nodes are shut down in a random order (by setting the associated row/column of the connectivity matrix to null vectors), and \n",
    " * one in which nodes are shut down starting with the ones exhibiting the larger degree. \n",
    " \n",
    "For an edge density of $0.3$, we will compute the average nodal clustering coefficient across nodes for each subject, incrementally removing a node at a time. \n",
    "\n",
    "Run the next cell to display the resulting curves, and compare both the random and specific shutting down cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell performs node removal for each subject's adjacency matrix and at each step calculates\n",
    "# the average (over nodes) clustering coefficient. This is repeated twice, for random node removal, and\n",
    "# for removal of the node with the highest degree\n",
    "\n",
    "rho = 0.3\n",
    "c_rem = np.zeros((54,89))\n",
    "c_rem_targ = np.zeros((54,89))\n",
    "for sub in range(0,54):\n",
    "    adj = BinarizeAdjacency(np.squeeze(ComputeAdjacency(TCS[sub,:,:])),rho).astype(int)\n",
    "    adj_targ = adj\n",
    "    for counter in range (1,90):\n",
    "        node = np.random.randint(0, adj.shape[0])\n",
    "        adj = np.delete(adj, node, 0)\n",
    "        adj = np.delete(adj, node, 1)\n",
    "        c_rem[sub, counter-1] = np.mean(ComputeC(adj))\n",
    "        \n",
    "        deg = adj_targ.dot(np.ones(adj_targ.shape[0],))\n",
    "        node = np.argmax(deg)\n",
    "        adj_targ = np.delete(adj_targ, node, 0)\n",
    "        adj_targ = np.delete(adj_targ, node, 1)\n",
    "        c_rem_targ[sub, counter-1] = np.mean(ComputeC(adj_targ))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the next cell to plot the node-averaged clustering coefficient versus number of nodes removed. \n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "    \n",
    "**Note:** Each subject's graph corresponds to two lines: one *blue-ish* for random node removal, and one *red-ish* for highest degree node removal.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for sub in range(0,54):\n",
    "    plt.plot(np.arange(1,90), c_rem[sub,:], color=[0,0.8,sub/54])\n",
    "    plt.plot(np.arange(1,90), c_rem_targ[sub,:], color=[sub/54,0.2,0.2])\n",
    "plt.xlabel(\"number of removed nodes\",fontsize=14)\n",
    "plt.ylabel(\"clustering coefficient\",fontsize=14)\n",
    "plt.title(\"node-averaged clustering coefficient for subject graphs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection point:\n",
    "\n",
    "Cold colors refer to the random node removal case, while warm colors denote targeted node removal, starting with the node with largest degree. We notice a gradual decrease of the clustering coefficient in all subject cases, which is logical as we gradually remove edges from the graph by excluding nodes. \n",
    "\n",
    "More importantly, we see that the targeted removal curves reach zero faster, which means that local information flow as quantified by the clustering coefficient suffers more from the exclusion of high-degree nodes from the network. \n",
    "\n",
    "This highlights the fact that there is a subset of brain regions that are particularly important to maintain correct brain functional architecture, because they are hubs that particularly strongly contribute to both local information flow, and long-distance interactions (for this reason, we would actually expect the same type of outcome if quantifying path length). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gender Classification\n",
    "\n",
    "We will now attempt to use a linear Support Vector Machine (*SVM*) framework in order to classify male and female subjects from our dataset according to their brain connectivity feature. This is a task that has already been undertaken by previous research work [see original paper](https://www.sciencedirect.com/science/article/pii/S105381191001058X). \n",
    "\n",
    "For this purpose, we resort to a leave-one-out cross-validation (*LOOCV*) framework with labels $0$ and $1$ for male and female subjects, respectively. In the present data, the first 27 subjects are male, and the second half of subjects are female.\n",
    "\n",
    "Look back at your [course notes](https://moodle.epfl.ch/pluginfile.php/1674937/mod_resource/content/8/7-ML.pdf) if you need to, and remember the principles of *LOOCV* and the reasons why it has to be used in this case. Also, briefly summarize the working principle of the linear SVM classification approach.\n",
    "\n",
    "As a first trial, we will attempt to classify our subjects on the basis of nodal clustering coefficient data: each data point is thus a 90-dimensional feature vector. For density values ranging from 0.05 to 0.95 by increments of 0.1, we compute the training and testing *LOOCV* errors, and plot the two output curves. We will use the function `train_svm` we declared at the beginning of the notebook.\n",
    "\n",
    "Run the next cell to clasify our subjects and plot the two error curves with respect to the edge density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_svm() useful function for gender classification using SVM (remember the theory from the lecture)\n",
    "\n",
    "def train_svm(X,labels):\n",
    "    Err_test=0.\n",
    "    Err_train_vec=np.zeros((X.shape[0],))\n",
    "    for i in range(0,X.shape[0]):\n",
    "        #split data into training and testing set (one sample)\n",
    "        data_train=np.delete(X, i, 0)\n",
    "        data_test=X[i,:].reshape(1, -1)\n",
    "        C_train=np.delete(labels, i, 0).ravel()\n",
    "        C_test=labels[i,:].reshape(1, -1)\n",
    "        #train and predict\n",
    "        model_svm_lin = LinearSVC(max_iter=5000,dual=True)\n",
    "        model_svm_lin.fit(data_train, C_train)\n",
    "        C_pred_lin_test = model_svm_lin.predict(data_test)\n",
    "        C_pred_lin_train = model_svm_lin.predict(data_train)\n",
    "        Err_train_vec[i,] = np.sum(np.abs(C_pred_lin_train-C_train))*100/X.shape[0]\n",
    "        if C_pred_lin_test!=C_test:\n",
    "            Err_test += 1.\n",
    "    \n",
    "    Err_test=100*Err_test/X.shape[0]\n",
    "    Err_train=np.mean(Err_train_vec)\n",
    "    return Err_test, Err_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section performs LOOCV gender classification using linear SVM and clustering coefficient as features\n",
    "etrain, etest = np.zeros((10,1)), np.zeros((10,1))\n",
    "for rho_ind in range(0,10):\n",
    "    X = np.squeeze(c[:, rho_ind, :])\n",
    "    labels = np.zeros((X.shape[0],1))\n",
    "    labels[27:,0] = 1\n",
    "    \n",
    "    #Perform linear SVM classification and store the test and training LOOCV errors for each rho_ind in etrain and etest\n",
    "    # etest, etrain = train_svm()\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    etest[rho_ind,0], etrain[rho_ind,0] = train_svm(X,labels)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(rho_vec, etrain,'b', label=\"training error\")\n",
    "plt.plot(rho_vec, etest,'r', label=\"testing error\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"edge density\",fontsize=14)\n",
    "plt.ylabel(\"prediction error\",fontsize=14)\n",
    "plt.title('Error curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to instead use functional connectivity values themselves for classification purposes. We extract them from the subject-wise connectivity matrices, and compute training and testing errors in this case. \n",
    "\n",
    "Run the next cell to perform this classification and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section performs LOOCV classification into male and female subjects\n",
    "#using linear SVM and vectorized functional connectivity matrices as features\n",
    "etrain, etest = np.zeros((10,1)), np.zeros((10,1))\n",
    "for rho_ind in range(0,10):\n",
    "    #build data matrix from functional connectivity\n",
    "    X=np.zeros((54,90*90))\n",
    "    for sub in range(0,54):\n",
    "        adj = BinarizeAdjacency(np.squeeze(ComputeAdjacency(TCS[sub,:,:])),rho_vec[rho_ind,0])\n",
    "        X[sub,:]=adj.reshape(1,-1)\n",
    "    labels=np.zeros((X.shape[0],1))\n",
    "    labels[27:,0]=1\n",
    "\n",
    "    #Perform linear SVM classification and store the test and training LOOCV errors for each rho_ind in etrain and etest\n",
    "    # etest, etrain = train_svm()\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    etest[rho_ind,0], etrain[rho_ind,0] = train_svm(X,labels)\n",
    "    ### END SOLUTION\n",
    "\n",
    "#This section plots the two error curves with respect to the edge density\n",
    "plt.figure()\n",
    "plt.plot(rho_vec, etrain,'b', label=\"training error\")\n",
    "plt.plot(rho_vec, etest,'r', label=\"testing error\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"edge density\",fontsize=14)\n",
    "plt.ylabel(\"prediction error\",fontsize=14)\n",
    "plt.title('Error curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "\n",
    "We should have applied a feature selection step before SVM training in order to reduce the risk of overfitting. The 0% error in the training set is due to clear overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (bonus) 5. Connectomes in comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go back to our **brain data**. Let's build a graph from the functional connectivity matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you recall the very first weeks, from dMRI it's possible to have a tractography and a structural connectome\n",
    "# Load the structural connectome and generate a structural graph from it using networkx. \n",
    "\n",
    "SC = scipy.io.loadmat(\"./FC_graphs_data/sub1_SC.mat\")\n",
    "SC = SC['sub1_SC']\n",
    "\n",
    "# Binarize the matrix -- threshold can be changed (explore also this if you want)\n",
    "SC_bin = np.copy(SC)\n",
    "SC_bin[SC>=250] = 1\n",
    "SC_bin[SC<250] = 0\n",
    "\n",
    "G_str = nx.from_numpy_array(SC_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the functional graph in the same way but inputting as adjacency matrix the binarized functional connectivity \n",
    "# defined in section 1 of subject 1 with an edge_density=0.1.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "#G_fun = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and visualize both Connectomes\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you say about the two matrices already? Visually inspect the two and consider the connections. You can also normalize the values to put the 2 matrices on the same scale. Use also a colorbar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two connectomes with a graph metric (e.g. local clustering coefficients)\n",
    "# this time it's different from the global clustering coefficient seen before\n",
    "\n",
    "loc_cc_fun = list(nx.clustering(G_fun).values())\n",
    "loc_cc_str = list(nx.clustering(G_str).values())\n",
    "\n",
    "# plot the two vectors with respect to the nodes\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loc_cc_fun, 'b', alpha=0.6)\n",
    "plt.plot(loc_cc_str, 'r', alpha=0.6)\n",
    "\n",
    "plt.legend({'Functional', 'Structural'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret these results: what can you say about each node?\n",
    "\n",
    "\n",
    "You can also extend this reasoning to any other graph metric. Try it to belive! ;-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
