{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Grasp classification using EMG signals to control a robotic hand prosthesis\n",
    "\n",
    "In this exercise you will process EMG signals in order to decode motor intentions of the user. \n",
    "\n",
    "We recorded an EMG dataset that consists of a user performing different single finger and multi-finger grasps. The subject was asked to follow a virtual hand and perform the same movements to synchronize EMG and finger movements.\n",
    "\n",
    "In the dataset available in the folder data_csv there are two csv files (EMG signals and finger positions). Finger values are 0 when a finger is opened, 1 at rest position and 2 when it is closed. We recorded 6 EMG channels at 2kHz and finger states at 60Hz.\n",
    "\n",
    "Finger states are saved as a matrix where rows correspond to time and columns correspond to one joint (Thump opposition, Thumb, Index, Middle, Ring, Pinky). See the following image:\n",
    "\n",
    "<img src=\"figures\\figures\\hand_model.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "The sequence of movements is made of the following movements held for 5 seconds with a rest position of 3 seconds in between everytime: pinky flexion, ulnar flexion, middle flexion, index flexion, thumb opposition, ulnar grasp, tri-digital grasp, pincer grasp, thumb up, lateral (key) grasp, power grasp, open (note that there is no rest position between thumb up and lateral grasp).\n",
    "\n",
    "You can see forearm muscle anatomy and function following these two links:\n",
    "\n",
    "- https://teachmeanatomy.info/upper-limb/muscles/posterior-forearm/\n",
    "- https://teachmeanatomy.info/upper-limb/muscles/anterior-forearm/\n",
    "\n",
    "This jupyter notebook will:\n",
    "- load the .csv files (EMG + Targets)\n",
    "- Plot the raw data for visual inspection\n",
    "- Synchronize EMG and Targets since they are recorded as two separate streams of data (2000kHz for the EMG and 60Hz for the Targets)\n",
    "\n",
    "The aim of this exercise is to design and explore different machine learning models capable of decoding user intentions to control a robotic prosthetic hand. You will have to assess performance on unseen data to quantify the accuracy expected in a real experiment.\n",
    "\n",
    "For the model to work in a real world scenario, the model should be fast enough to be able to decode motor intention with a small amount of data (200ms of signal is a standard value). We will use a sliding window to \"cut\" the data in samples that will be used to make the classification. The windows are overlapped to increase the amount of samples to train the model (see https://doi.org/10.3390/s19204596 chapter 3.2). \n",
    "\n",
    "However, the signal itself is usually too complex to train a machine learning model. A standard approach to train a classifier is to extract meaninful and discriminative features from the signal and use it to train the model (See https://doi.org/10.3390/s19204596 and https://doi.org/10.1088/0967-3334/24/2/307).\n",
    "\n",
    "You can choose the model type and classification type (see https://scikit-learn.org/stable/modules/multiclass.html). You are free to choose the classification type (multi-class, multi-output,...) depending on how you will prepare the targets.\n",
    "\n",
    "Therefore, you will have to:\n",
    "- Divide the whole dataset into the three following sets: Training, Validation and Testing set.\n",
    "- Extract sliding windows of 200ms from the EMG signal with an overlap of 50ms and prepare the Targets as the grasp type at the end of the time window.\n",
    "- Adapt targets for grasp classification\n",
    "- Extract meaningful information from raw EMG data (Feature extraction)\n",
    "- Create and compare different machine learning models to decode user intention\n",
    "- Evaluate performance of the final model you chose\n",
    "- Plot predictions made by your model\n",
    "\n",
    "The following figure summurize the different steps required to obtain an real-time EMG decoder:\n",
    "!['title'](figures/figures\\figure_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.signal import butter\n",
    "from scipy.signal import sosfiltfilt\n",
    "import time\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from align import align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 0.2 #200 ms\n",
    "sliding_step = 0.05 #50 ms\n",
    "sampling_frequency_EMG = 2000 #Hz   \n",
    "sampling_frequency_Targets = 60 #Hz   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Load the files\n",
    "\n",
    "Run the commented code to download the data if you haven't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown\n",
    "# import gdown\n",
    "# url = \"https://drive.google.com/uc?id=1gYq_L50vXhEHIURerpW-IluyzgPrOWFZ\"\n",
    "# output = \"EMG.csv\"\n",
    "# gdown.download(url, output, quiet = False)\n",
    "# url = \"https://drive.google.com/uc?id=1WoJA80wRaf2_LJv_BtazGQ6V11F0n8iR\"\n",
    "# output = \"action_list.npy\"\n",
    "# gdown.download(url, output, quiet = False)\n",
    "# url = \"https://drive.google.com/uc?id=1TUy0V40Rvj9mR39T9JFtgIEP6Fut7luq\"\n",
    "# output = \"Kinematics.csv\"\n",
    "# gdown.download(url, output, quiet = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMG_file_name='./EMG.csv'\n",
    "target_file_name='./Kinematics.csv'\n",
    "\n",
    "EMG_df = pd.read_csv(EMG_file_name,index_col='index')\n",
    "Targets_df = pd.read_csv(target_file_name,index_col='index')\n",
    "Targets_df = (Targets_df*2).astype(int) #convert into 0, 1, and 2 for label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMG_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of channels and number of samples\n",
    "n_channels = EMG_df.shape[1]\n",
    "n_samples = EMG_df.shape[0]\n",
    "\n",
    "# Convert into numpy array for easier manipulation\n",
    "EMG = np.array(EMG_df.values)\n",
    "\n",
    "Targets = np.array(Targets_df.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data with a bandpass filter\n",
    "Wn = (5, 500) \n",
    "sos = butter(N=8, Wn=Wn, fs=sampling_frequency_EMG, btype=\"bandpass\", output=\"sos\") \n",
    "EMG = sosfiltfilt(sos, EMG.T).T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Plot EMG data\n",
    "\n",
    "fig,ax = plt.subplots(n_channels,1,figsize = (16,16))\n",
    "t = np.arange(0,EMG.shape[0])/sampling_frequency_EMG\n",
    "for i in range(EMG.shape[1]):\n",
    "    ax[i].plot(t, EMG[:,i])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "    ax[i].set_ylabel('EMG Amplitude [mV]')\n",
    "    ax[i].set_xlabel('Time [s]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combinations = Targets_df.groupby(list(Targets_df.columns)).size().reset_index().rename(columns={0:'count'})\n",
    "Actions_list = ['Open','Pinky grasp','Ring grasp','Ulnar grasp','Middle grasp','Index grasp','Thumb up','Key grasp','Rest','Thumb grasp','Pincer grasp','Tridigital grasp','Power grasp']\n",
    "\n",
    "Combinations['Actions'] = Actions_list\n",
    "Combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above you can see the actions that the subject was asked to perform, and the corresponding target states of the fingers. For example in row 0, the subject was asked to open the hand (see in Action column) and therefore all the target channels are 0. In row 1, the action was pinky grasp, therefore we see that only target channel 6 has a value of 2. In row 11, the action was tridigital grasp, corresponding to closing target channels 1-4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate Targets\n",
    "Align EMG and Targets (interpolate Targets to obtain same sampling frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EMG_df, Targets_df = align(EMG_df,Targets_df)\n",
    "\n",
    "#convert into numpy array again for easier manipulation\n",
    "EMG = np.array(EMG_df.values)\n",
    "Targets = np.array(Targets_df.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous segments, we have the information about the target channels, for this exercise, we will focus on classifying the actions itself rather than individual fingers. Hence, we will map the target channels to the corresponding actions. We have done this for you so you can just load the list of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load action list\n",
    "Labels = np.load('./action_list.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print the shapes to make sure that they are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EMG.shape)\n",
    "print(Targets.shape)\n",
    "print(Labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut the dataset\n",
    "\n",
    "We will cut data into Training, Validation and Testing sets and extract windows. Since there are 6 repetition on each movement we will keep the last repetition for testing and the one before (5th repetition) for the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nth_repetition(Labels,n):\n",
    "    \"\"\"\n",
    "    This function is defined to find the nth repetition of a given action\n",
    "    :param action: string containing the action to be found\n",
    "    :param n: integer containing the number of repetition to be found\n",
    "    :return: integer containing the index of the nth repetition of the given action\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_actions = np.unique(Labels)\n",
    "    action_indices = {action: [] for action in unique_actions}\n",
    "    last_action = None\n",
    "\n",
    "    for i, action in enumerate(Labels):\n",
    "        if action != last_action:\n",
    "            action_indices[action].append(i)\n",
    "            last_action = action\n",
    "    \n",
    "    nth_repeat_indices = {}\n",
    "    for action, indices in action_indices.items():\n",
    "        if len(indices) >= n:\n",
    "            nth_repeat_indices[action] = indices[n-1]\n",
    "        else:\n",
    "            nth_repeat_indices[action] = None \n",
    "    \n",
    "    return nth_repeat_indices\n",
    "\n",
    "\n",
    "def cut_datasets(EMG, Labels,val_cut, test_cut):\n",
    "\n",
    "    \"\"\"\n",
    "    This function is defined to cut the data in three sets\n",
    "    :param EMG: pandas DataFrame containing the data\n",
    "    :param Targets: pandas DataFrame containing the targets\n",
    "    :param val_cut: information on how/where to cut the dataset to obtain the validation set\n",
    "    :param test_cut: information on how/where to cut the dataset to obtain the test set\n",
    "    :return: 6 pandas DataFrames (or numpy arrays) containing EMG and targets of each sets\n",
    "    \"\"\"\n",
    "\n",
    "    EMG_train = EMG[:val_cut]\n",
    "    EMG_val = EMG[val_cut:test_cut]\n",
    "    EMG_test = EMG[test_cut:]\n",
    "    Labels_train = Labels[:val_cut]\n",
    "    Labels_val = Labels[val_cut:test_cut]\n",
    "    Labels_test = Labels[test_cut:]\n",
    "\n",
    "\n",
    "    return EMG_train, EMG_val, EMG_test, Labels_train, Labels_val, Labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cut = find_nth_repetition(Labels,5)\n",
    "test_cut = find_nth_repetition(Labels,6)\n",
    "print(val_cut)\n",
    "print(test_cut)\n",
    "\n",
    "# Sort the nth repetition by values to find first action of that repetition. This is so that we can cut the dataset later\n",
    "val_cut = {k: v for k, v in sorted(val_cut.items(), key=lambda item: item[1])}\n",
    "test_cut = {k: v for k, v in sorted(test_cut.items(), key=lambda item: item[1])}\n",
    "print(val_cut)\n",
    "print(test_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the pinky grasp is the first action of each repetitions (we do not consider resting). We will use this information to cut the dataset in the following part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cut dataset into train, validation and test\n",
    "EMG_train, EMG_val, EMG_test, Labels_train, Labels_val, Labels_test = cut_datasets(EMG, Labels,val_cut['Pinky grasp'], test_cut['Pinky grasp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the proportion of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Percentage of training set: {EMG_train.shape[0]/EMG.shape[0]*100:.2f}%')\n",
    "print(f'Percentage of validation set: {EMG_val.shape[0]/EMG.shape[0]*100:.2f}%')\n",
    "print(f'Percentage of test set: {EMG_test.shape[0]/EMG.shape[0]*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Windows\n",
    "\n",
    "Now, you have to perform an overlapping sliding window with windows of 200ms and a step of 50ms (150ms overlap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_windows(EMG,Labels, fs,win_len,step):\n",
    "# This function is used to cut the time windows from the raw EMG \n",
    "# It return an array containing the EMG of each time window.\n",
    "# It also returns the labels corresponding to the time of the end of the window\n",
    "    \"\"\"\n",
    "    This function is defined to perform an overlapping sliding window \n",
    "    :param EMG: numpy array containing the data\n",
    "    :param Labels: numpy array containing the labels\n",
    "    :param fs: the sampling frequency of the signal\n",
    "    :param win_len: The size of the windows (in seconds)\n",
    "    :param step: The step size between windows (in seconds)\n",
    "    :return: A numpy arrays containing the windows\n",
    "    :return: A numpy array containing the labels aligned for each window\n",
    "    :note: The length of both outputs should be the same\n",
    "    \"\"\"\n",
    "    \n",
    "    n,m = EMG.shape\n",
    "    win_len = int(win_len*fs)\n",
    "    start_points = np.arange(0,n-win_len,int(step*fs))\n",
    "    end_points = start_points + win_len\n",
    "\n",
    "    EMG_windows = np.zeros((len(start_points),win_len,m))\n",
    "    Labels_window = [] \n",
    "    for i in range(len(start_points)):\n",
    "        EMG_windows[i,:,:] = EMG[start_points[i]:end_points[i],:]\n",
    "        Labels_window.append(Labels[start_points[i]])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return EMG_windows, np.array(Labels_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extract sliding windows\n",
    " \n",
    "train_EMG_window, train_Labels_window = extract_time_windows(EMG_train,Labels_train, sampling_frequency_EMG,window_length,sliding_step)\n",
    "\n",
    "val_EMG_window, val_Labels_window = extract_time_windows(EMG_val,Labels_val, sampling_frequency_EMG,window_length,sliding_step)\n",
    "\n",
    "test_EMG_window, test_Labels_window = extract_time_windows(EMG_test,Labels_test, sampling_frequency_EMG,window_length,sliding_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Now you will have to extract meaningful information from each EMG channel to be able to decode user intention.\n",
    "\n",
    "Time features: \n",
    "\n",
    "- Mean absolute value (MAV)\n",
    "- Maximum absolute Value (MaxAV)\n",
    "- Wavelength (WL): cumulative length of the waveform over time\n",
    "- Standard Deviation (STD)\n",
    "- Root mean square (RMS)\n",
    "- Zero crossing (ZC): number of times the signal crosses zero\n",
    "- Slope sign changes (SSC): number of times the slope of the EMG changes signs\n",
    "\n",
    "Frequency features: \n",
    "\n",
    "- Mean power \n",
    "- Total power\n",
    "- Mean frequency\n",
    "- Median frequency \n",
    "- Peak frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fft_power(EMG_windows, fs):\n",
    "    N = EMG_windows.shape[1]  # Number of points in each window\n",
    "    freqs = np.fft.rfftfreq(N, 1/fs)  # Frequency bins\n",
    "\n",
    "    # Fast Fourier Transform (FFT)\n",
    "    fft_vals = np.fft.rfft(EMG_windows, axis=1)\n",
    "    fft_power = np.abs(fft_vals) ** 2  # Power spectrum\n",
    "    return freqs[1:], fft_power[:,1:,:]\n",
    "\n",
    "\n",
    "def extract_features(EMG_windows, fs):\n",
    "    \"\"\"\n",
    "    This function extracts features from raw EMG data. \n",
    "    The output matrix containing the features is called X (N_windows*N_features)\n",
    "    Each feature you decide to extract should be extracted for each EMG channel of each window\n",
    "    :param windows: List of pandas DataFrames (or numpy arrays) containing the windows\n",
    "    :return: The matrix X\n",
    "    \"\"\"\n",
    "    # Mean absolute value (MAV)\n",
    "    mav =  #???\n",
    "\n",
    "    # Maximum absolute Value (MaxAV)\n",
    "    maxav = #???\n",
    "\n",
    "    # Standard Deviation (STD)\n",
    "    std = #???\n",
    "\n",
    "    # Root mean square (RMS)\n",
    "    rms = #???\n",
    "\n",
    "    # Wavelength (WL)\n",
    "    wl = np.sum(np.abs(np.diff(EMG_windows, axis=1)), axis=1) \n",
    "\n",
    "    # Zero crossing (ZC) (hint: you can use np.diff and np.sign to evaluate the zero crossing, then sum the occurance)\n",
    "    zc = #???\n",
    "\n",
    "    # Slope sign changes (SSC)\n",
    "    diff = np.diff(EMG_windows, axis=1)\n",
    "    ssc = #???\n",
    "\n",
    "    # Get frequency and spectrogram power \n",
    "    freqs, fft_power = calc_fft_power(EMG_windows, fs=fs)\n",
    "\n",
    "    # Mean power \n",
    "    mean_power = #???\n",
    "\n",
    "    # Total power\n",
    "    tot_power = #???\n",
    "\n",
    "    # Mean frequency (sum of the product of spectrogram power and frequency, divided by total sum of spectrogram power)\n",
    "    freqs_reshaped = freqs.reshape(1, freqs.shape[0], 1) #reshape for multiplication of spectrogram power and frequency \n",
    "    mean_frequency = #???\n",
    "\n",
    "    # Median frequency \n",
    "    cumulative_power = np.cumsum(fft_power, axis=1)\n",
    "    total_power = cumulative_power[:, -1, :]\n",
    "    median_frequency = np.zeros((EMG_windows.shape[0],EMG_windows.shape[2]))\n",
    "\n",
    "    for i in range(EMG_windows.shape[0]):\n",
    "        for j in range(EMG_windows.shape[2]):\n",
    "            median_frequency[i,j] = freqs[np.where(cumulative_power[i, :, j] >= total_power[i,j] / 2)[0][0]]\n",
    "\n",
    "    # Peak frequency (use np.argmax)\n",
    "    peak_frequency = #???\n",
    "\n",
    "\n",
    "    X = np.column_stack((mav, maxav, std, rms, wl, zc, ssc, mean_power, tot_power, mean_frequency, median_frequency, peak_frequency))\n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exctract features from training and testing sets\n",
    "X_train = extract_features(train_EMG_window, sampling_frequency_EMG)\n",
    "y_train = train_Labels_window\n",
    "\n",
    "X_val = extract_features(val_EMG_window, sampling_frequency_EMG)\n",
    "y_val = val_Labels_window\n",
    "\n",
    "X_test = extract_features(test_EMG_window, sampling_frequency_EMG)\n",
    "y_test = test_Labels_window\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Standardization\n",
    "\n",
    "Usually the features are re-scaled either between two bounded values or standardized (e.g $\\frac{(x-\\mu)}{\\sigma}$). We provide the code to perform this step. We extract the mean and standard deviation of each feature from the training set and re-scale the features of all the sets with these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_scaler = StandardScaler().fit(X_train)\n",
    "X_train_z = Feature_scaler.transform(X_train[:,:])\n",
    "X_val_z = Feature_scaler.transform(X_val[:,:])\n",
    "X_test_z = Feature_scaler.transform(X_test[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we doing this step?\n",
    "\n",
    "Explain why it is performed like this and not on all features directly.\n",
    "\n",
    "Do you see any limitation of this approach for real time use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the features\n",
    "fig,ax = plt.subplots(1,1,figsize = (16,16))\n",
    "sns.heatmap(X_train_z[:,:],ax=ax, vmin = -4, vmax = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that the SSC (Slope Sign Changes) feature can often appear quite noisy. A common approach to enhance its robustness is by integrating a threshold within the slope sign change computation. If you're interested in exploring the impact of this modification, you can incorporate the following code snippet into the extract_features(EMG_windows, fs) function. This will allow you to compare the outcomes with and without the use of a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold=0.01\n",
    "# ssc = np.zeros((EMG_windows.shape[0],EMG_windows.shape[2]))\n",
    "# for i in range(EMG_windows.shape[0]):\n",
    "#     for j in range(EMG_windows.shape[2]):\n",
    "#         # Calculate SSC with threshold\n",
    "#         ssc[i, j] = np.sum((np.abs(diff[i, :-1, j]) >= threshold) &\n",
    "#                        (np.abs(diff[i, 1:, j]) >= threshold) &\n",
    "#                        (np.sign(diff[i, :-1, j]) != np.sign(diff[i, 1:, j])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot the correlation matrix of the features\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize = (16,16))\n",
    "sns.heatmap(np.corrcoef(X_train_z[:,:].T),ax=ax, vmin = -1, vmax = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, it is good practice to shuffle the training samples (windows) to improve the training of decoders trained with iterative process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shuffle, y_train_shuffle = sklearn.utils.shuffle(X_train_z, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use SVC from sklearn for the classification. Use the fit and predict methods of the classifier.\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "###########################################\n",
    "################## TODO ###################\n",
    "###########################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation \n",
    "    \n",
    "Let's evaluate the performance of the model and plot results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the metrics available in sklearn to evaluate the performance of the model. \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy = #???\n",
    "print(f\"Accuracy of the classification {accuracy}\")\n",
    "\n",
    "confmat = #???\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(confmat, ax=ax)\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude from the accuracy and confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction / Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following our initial classification using the extracted EMG features, we now move to an advanced stage of our analysis: feature selection and reduction. This process is aimed at refining our model by identifying and retaining the most informative features while discarding those that contribute less to the classification accuracy. After applying these techniques, we will perform another round of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train_z)\n",
    "residual_variance = pca.explained_variance_ratio_.cumsum()\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot( residual_variance)\n",
    "ax.set_xlabel(\"Number of retained PCs\")\n",
    "ax.set_ylabel(\"Cumulative explained variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot illustrates how the variance explained in our data changes with the number of features we retain. This could help in selecting the optimal number of features for our analysis.\n",
    "Typically, we select the number of principal components that explains 90/95% of the variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_train_z)\n",
    "\n",
    "X_train_PCA = pca.transform(X_train_z)\n",
    "X_val_PCA = pca.transform(X_val_z)\n",
    "X_test_PCA = pca.transform(X_test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shuffle, y_train_shuffle = sklearn.utils.shuffle(X_train_PCA, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use SVC from sklearn for the classification. Use the fit and predict methods of the classifier.\n",
    "\n",
    "###########################################\n",
    "################## TODO ###################\n",
    "###########################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the compute the accuracy and plot the confusion matrix.\n",
    "\n",
    "accuracy = #???\n",
    "print(accuracy)\n",
    "\n",
    "confmat = #???\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(confmat, ax=ax)\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude after performing feature selection? Does the classification improve? What can be other advantages of applying PCA for classification?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
